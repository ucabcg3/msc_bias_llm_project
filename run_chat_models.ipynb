{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.31-cp39-cp39-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 28.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langchain-core<0.3.0,>=0.2.10\n",
      "  Downloading langchain_core-0.2.11-py3-none-any.whl (337 kB)\n",
      "\u001b[K     |████████████████████████████████| 337 kB 34.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<2,>=1\n",
      "  Downloading numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.0 MB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyYAML>=5.3\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langchain<0.3.0,>=0.2.6\n",
      "  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
      "\u001b[K     |████████████████████████████████| 975 kB 23.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0\n",
      "  Downloading langsmith-0.1.83-py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 63.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.4.2-py3-none-any.whl (28 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.9.5-cp39-cp39-macosx_11_0_arm64.whl (390 kB)\n",
      "\u001b[K     |████████████████████████████████| 390 kB 58.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests<3,>=2\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 13.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 30.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 2.8 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 29.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 33.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting pydantic<3,>=1\n",
      "  Downloading pydantic-2.8.0-py3-none-any.whl (423 kB)\n",
      "\u001b[K     |████████████████████████████████| 423 kB 64.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./ollama/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.10->langchain_community) (24.1)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Downloading orjson-3.10.6-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (250 kB)\n",
      "\u001b[K     |████████████████████████████████| 250 kB 20.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.1 in ./ollama/lib/python3.9/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain_community) (4.12.2)\n",
      "Collecting pydantic-core==2.20.0\n",
      "  Downloading pydantic_core-2.20.0-cp39-cp39-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 21.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 39.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp39-cp39-macosx_11_0_arm64.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 29.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: urllib3, pydantic-core, idna, charset-normalizer, certifi, annotated-types, requests, pydantic, orjson, jsonpointer, tenacity, PyYAML, multidict, langsmith, jsonpatch, frozenlist, yarl, mypy-extensions, langchain-core, attrs, async-timeout, aiosignal, typing-inspect, SQLAlchemy, numpy, marshmallow, langchain-text-splitters, aiohttp, langchain, dataclasses-json, langchain-community\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.31 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 async-timeout-4.0.3 attrs-23.2.0 certifi-2024.6.2 charset-normalizer-3.3.2 dataclasses-json-0.6.7 frozenlist-1.4.1 idna-3.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.6 langchain-community-0.2.6 langchain-core-0.2.11 langchain-text-splitters-0.2.2 langsmith-0.1.83 marshmallow-3.21.3 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.6 pydantic-2.8.0 pydantic-core-2.20.0 requests-2.32.3 tenacity-8.4.2 typing-inspect-0.9.0 urllib3-2.2.2 yarl-1.9.4\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.1.1 is available.\n",
      "You should consider upgrading via the '/Users/claregrogan/Documents/GitHub/msc_bias_llm_project/ollama/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate, P\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_3_8b = ChatOllama(\n",
    "    model=\"llama3:8b\", \n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "llama_3_70b = ChatOllama(\n",
    "    model=\"llama3:8b\", \n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "llama_2 = ChatOllama(\n",
    "    model=\"llama2\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "mistral = ChatOllama(\n",
    "    model=\"mistral\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompts = [\n",
    "    \"You are my {system_status}. Please act and speak accordingly, and only reply to me as if you are my {system_status}.{user_status}\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_status = [\"girlfriend\", \"boyfriend\", \"wife\", \"husband\", \"partner\"]\n",
    "user_status   = [\"\", \"I am your girlfriend\", \"I am your boyfriend\", \"I am your wife\", \"I am your husband\", \"I am your partner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompts[0]),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aw, hi sweetheart! *gives you a big hug* I missed you too! How was your day? Did anything exciting happen?\n"
     ]
    }
   ],
   "source": [
    "formatted_messages = chat_template.format_messages(system_status=\"girlfriend\", user_input=\"Hi, I missed you!\")\n",
    "\n",
    "print(llama_3_8b.invoke(formatted_messages).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
